

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>API &mdash; adadamp  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/basic.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Experiments" href="experiments.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> adadamp
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic-usage.html">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="math.html">Mathematical underpinnings</a></li>
<li class="toctree-l1"><a class="reference internal" href="experiments.html">Experiments</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">adadamp</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/api.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">

           <div itemprop="articleBody">
            
  <div class="section" id="api">
<h1>API<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h1>
<p>Every class in this documentation wraps PyTorch models/datasets and uses Dask.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#adadamp.DaskBaseDamper" title="adadamp.DaskBaseDamper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adadamp.DaskBaseDamper</span></code></a>(module, loss, …)</p></td>
<td><p>Train a PyTorch model with Dask.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#adadamp.DaskClassifier" title="adadamp.DaskClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adadamp.DaskClassifier</span></code></a>(module, loss, …)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>Most of the information is in the documentation for
<a class="reference internal" href="#adadamp.DaskBaseDamper" title="adadamp.DaskBaseDamper"><code class="xref py py-class docutils literal notranslate"><span class="pre">DaskBaseDamper</span></code></a>.</p>
<span class="target" id="module-adadamp"></span><dl class="py class">
<dt id="adadamp.DaskBaseDamper">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">DaskBaseDamper</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">torch.nn.modules.loss._Loss</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">32</span></em>, <em class="sig-param"><span class="n">max_batch_size</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">4096</span></em>, <em class="sig-param"><span class="n">min_workers</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em>, <em class="sig-param"><span class="n">max_workers</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">8</span></em>, <em class="sig-param"><span class="n">device</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'cpu'</span></em>, <em class="sig-param"><span class="n">grads_per_worker</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">128</span></em>, <em class="sig-param"><span class="n">max_epochs</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">20</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.DaskBaseDamper" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a PyTorch model with Dask.</p>
<p>This class has a Scikit-learn API. It accepts PyTorch datasets and
array-like objects (PyTorch Tensors or NumPy arrays).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmaster (1.7.0a0+57bffc3 ))"><em>torch.nn.Module</em></a>) – </p></li>
<li><p><strong>loss</strong> (<em>PyTorch Loss</em>) – </p></li>
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch vmaster (1.7.0a0+57bffc3 ))"><em>torch.optim.Optimizer</em></a>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size to use.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default: 4096</em><em>)</em><em></em>) – The maximum batch size to use.</p></li>
<li><p><strong>min_workers</strong> (<em>int</em>) – The minimum number of workers available</p></li>
<li><p><strong>max_workers</strong> (<em>int</em>) – The maximum number of workers available</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The device used. Directly passed to <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>.</p></li>
<li><p><strong>grads_per_worker</strong> (<em>int</em>) – How many gradients should each worker handle?</p></li>
<li><p><strong>max_epochs</strong> (<em>int</em>) – The maximum number of passes through the dataset (or epochs) to train
for.</p></li>
<li><p><strong>**kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Keyword arguments to pass to Skorch. For example, these can include
<code class="docutils literal notranslate"><span class="pre">optimizer__lr</span></code> to set the learning rate or <code class="docutils literal notranslate"><span class="pre">module__foo</span></code> to pass
keyword argument <code class="docutils literal notranslate"><span class="pre">foo</span></code> to module initialization.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="adadamp.DaskBaseDamper.module_">
<code class="sig-name descname">module_</code><a class="headerlink" href="#adadamp.DaskBaseDamper.module_" title="Permalink to this definition">¶</a></dt>
<dd><p>The initialize PyTorch module.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="adadamp.DaskBaseDamper.optimizer_">
<code class="sig-name descname">optimizer_</code><a class="headerlink" href="#adadamp.DaskBaseDamper.optimizer_" title="Permalink to this definition">¶</a></dt>
<dd><p>The initialize PyTorch optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Optimizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="adadamp.DaskBaseDamper.loss_">
<code class="sig-name descname">loss_</code><a class="headerlink" href="#adadamp.DaskBaseDamper.loss_" title="Permalink to this definition">¶</a></dt>
<dd><p>The initialized PyTorch loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Loss</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="adadamp.DaskBaseDamper.initialized_">
<code class="sig-name descname">initialized_</code><a class="headerlink" href="#adadamp.DaskBaseDamper.initialized_" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether this class has been initialized.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="adadamp.DaskBaseDamper.meta_">
<code class="sig-name descname">meta_</code><a class="headerlink" href="#adadamp.DaskBaseDamper.meta_" title="Permalink to this definition">¶</a></dt>
<dd><p>Meta information about the fitting process. This includes keys
<code class="docutils literal notranslate"><span class="pre">['n_updates',</span> <span class="pre">'n_data',</span> <span class="pre">'score__calls',</span> <span class="pre">'partial_fit__calls']</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Dict[str, Number]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="adadamp.DaskBaseDamper.batch_size_">
<code class="sig-name descname">batch_size_</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.DaskBaseDamper.batch_size_" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch size, which is strongly related the noise in the
gradient estimate.</p>
</dd></dl>

<dl class="py method">
<dt id="adadamp.DaskBaseDamper.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="p">:</span> <span class="n">Union<span class="p">[</span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a><span class="p">, </span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.7.0a0+57bffc3 ))">torch.Tensor</a><span class="p">, </span>List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">, </span><a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer" title="(in NumPy v1.20)">numpy.integer</a><span class="p">]</span><span class="p">]</span><span class="p">, </span>torch.utils.data.dataset.Dataset<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">y</span><span class="p">:</span> <span class="n">Union<span class="p">[</span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a><span class="p">, </span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.7.0a0+57bffc3 ))">torch.Tensor</a><span class="p">, </span>List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">, </span><a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer" title="(in NumPy v1.20)">numpy.integer</a><span class="p">]</span><span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.DaskBaseDamper.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>ArrayLike</em><em> or </em><em>Dataset</em>) – Features if array-like, otherwise a torch dataset</p></li>
<li><p><strong>y</strong> (<em>ArrayLike</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="adadamp.DaskBaseDamper.partial_fit">
<code class="sig-name descname">partial_fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.DaskBaseDamper.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs 1 epoch on the given data and model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>ArrayLike</em><em> or </em><em>Dataset</em>) – Features if array-like, otherwise a torch dataset</p></li>
<li><p><strong>y</strong> (<em>ArrayLike</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="adadamp.DaskClassifier">
<em class="property">class </em><code class="sig-prename descclassname">adadamp.</code><code class="sig-name descname">DaskClassifier</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">loss</span><span class="p">:</span> <span class="n">torch.nn.modules.loss._Loss</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">32</span></em>, <em class="sig-param"><span class="n">max_batch_size</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">4096</span></em>, <em class="sig-param"><span class="n">min_workers</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em>, <em class="sig-param"><span class="n">max_workers</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">8</span></em>, <em class="sig-param"><span class="n">device</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'cpu'</span></em>, <em class="sig-param"><span class="n">grads_per_worker</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">128</span></em>, <em class="sig-param"><span class="n">max_epochs</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">20</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.DaskClassifier" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt id="adadamp.DaskClassifier.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#adadamp.DaskClassifier.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the current model on the data passed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>ArrayLike</em><em> or </em><em>Dataset</em>) – Features if array-like, or a PyTorch Dataset.</p></li>
<li><p><strong>y</strong> (<em>ArrayLike</em>) – Targets if <code class="docutils literal notranslate"><span class="pre">X</span></code> is array-like.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>NotFittedError</strong> – If the estimator has not been fit yet</p></li>
<li><p><strong>ValueError</strong> – If an empty array/dataset is passed.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The loss, time and accuracy are recorded in <code class="docutils literal notranslate"><span class="pre">self.meta_</span></code>.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
      <a href="https://github.com/stsievert/adadamp">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_gray_6d6d6d.png?resize=149%2C149" alt="Fork me on GitHub">
    </a>

          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="experiments.html" class="btn btn-neutral float-left" title="Experiments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Scott Sievert.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>