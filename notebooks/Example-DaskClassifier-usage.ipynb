{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage for DaskClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # make notebook assume its in parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from adadamp import DaskClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model from https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, n_epochs, log_every=100):\n",
    "    # per batch stats\n",
    "    # - losses = loss for batch\n",
    "    # - time_for_batch = time to proccess batch\n",
    "    # - params = params during this batch\n",
    "    # - batch_idx = index of current batch\n",
    "\n",
    "    log_interval = log_every\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        accs = []\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            model.fit(data, target)\n",
    "\n",
    "            # outs = 64x\n",
    "            new_acc = model.score(data, target) # Expected input batch_size (640) to match target batch_size (64).\n",
    "\n",
    "            accs += [new_acc]\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tAccuracy: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), sum(accs) / len(accs) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "device = torch.device(\"cpu\")\n",
    "log_interval = 10\n",
    "train_kwargs = {'batch_size': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "dataset1 = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST('./data', train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DaskClassifier(module=Net, loss=nn.NLLLoss, optimizer=optim.Adadelta, optimizer__lr=1.0, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tAccuracy: 0.968750\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tAccuracy: 0.965037\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tAccuracy: 0.969139\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tAccuracy: 0.973214\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tAccuracy: 0.975608\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tAccuracy: 0.976734\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tAccuracy: 0.977901\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tAccuracy: 0.978803\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tAccuracy: 0.979635\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tAccuracy: 0.980577\n",
      "Train Epoch: 2 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tAccuracy: 0.988707\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tAccuracy: 0.988029\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tAccuracy: 0.988320\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tAccuracy: 0.988895\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tAccuracy: 0.988991\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tAccuracy: 0.989445\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tAccuracy: 0.989479\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tAccuracy: 0.989583\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tAccuracy: 0.989855\n",
      "Train Epoch: 3 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tAccuracy: 0.993657\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tAccuracy: 0.992537\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tAccuracy: 0.992369\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tAccuracy: 0.991895\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tAccuracy: 0.991985\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tAccuracy: 0.992045\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tAccuracy: 0.991887\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tAccuracy: 0.991573\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tAccuracy: 0.991780\n",
      "Train Epoch: 4 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tAccuracy: 0.991182\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tAccuracy: 0.992382\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tAccuracy: 0.992369\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tAccuracy: 0.992558\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tAccuracy: 0.992671\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tAccuracy: 0.992616\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tAccuracy: 0.992578\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tAccuracy: 0.992704\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tAccuracy: 0.992942\n",
      "Train Epoch: 5 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tAccuracy: 0.992884\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tAccuracy: 0.992382\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tAccuracy: 0.992681\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tAccuracy: 0.992830\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tAccuracy: 0.993232\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tAccuracy: 0.993214\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tAccuracy: 0.993246\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tAccuracy: 0.993036\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tAccuracy: 0.993202\n",
      "Train Epoch: 6 [0/60000 (0%)]\tAccuracy: 0.984375\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tAccuracy: 0.994276\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tAccuracy: 0.993859\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tAccuracy: 0.994290\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tAccuracy: 0.994311\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tAccuracy: 0.994106\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tAccuracy: 0.993916\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tAccuracy: 0.993826\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tAccuracy: 0.993621\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tAccuracy: 0.993688\n",
      "Train Epoch: 7 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tAccuracy: 0.993193\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tAccuracy: 0.993237\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tAccuracy: 0.994030\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tAccuracy: 0.994350\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tAccuracy: 0.994230\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tAccuracy: 0.993760\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tAccuracy: 0.993803\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tAccuracy: 0.993446\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tAccuracy: 0.993653\n",
      "Train Epoch: 8 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tAccuracy: 0.993812\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tAccuracy: 0.994325\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tAccuracy: 0.993926\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tAccuracy: 0.993999\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tAccuracy: 0.993669\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tAccuracy: 0.993708\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tAccuracy: 0.993915\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tAccuracy: 0.993953\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tAccuracy: 0.994156\n",
      "Train Epoch: 9 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tAccuracy: 0.993193\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tAccuracy: 0.993315\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tAccuracy: 0.993407\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tAccuracy: 0.993766\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tAccuracy: 0.993669\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tAccuracy: 0.993812\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tAccuracy: 0.993737\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tAccuracy: 0.993621\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tAccuracy: 0.993566\n",
      "Train Epoch: 10 [0/60000 (0%)]\tAccuracy: 1.000000\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tAccuracy: 0.996132\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tAccuracy: 0.995336\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tAccuracy: 0.995432\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tAccuracy: 0.995675\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tAccuracy: 0.995259\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tAccuracy: 0.995164\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tAccuracy: 0.994896\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tAccuracy: 0.994772\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tAccuracy: 0.994763\n"
     ]
    }
   ],
   "source": [
    "train(model, device, train_loader, 10, log_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, batch = model.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json = {\n",
    "    'meta': meta,\n",
    "    'batch': batch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./notebooks/stats_10epoch.json', 'w') as fp:\n",
    "    json.dump(save_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adadamp",
   "language": "python",
   "name": "adadamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
