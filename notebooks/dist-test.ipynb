{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests to see if classifier works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "DIR = Path(\".\").absolute()\n",
    "sys.path.append(str(DIR))\n",
    "os.chdir(str(DIR.parent)) # make notebook assume its in parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from model import Net\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/distributed/dashboard/core.py:79: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://172.31.40.124/4400/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.31.40.124:42447/status' target='_blank'>http://172.31.40.124:42447/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.48 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://172.31.40.124/4400/1' processes=1 threads=4, memory=16.48 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "def _prep():\n",
    "    from distributed.protocol import torch\n",
    "\n",
    "client = Client(processes=False)\n",
    "client.run(_prep)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_weights(model):\n",
    "    s = 0\n",
    "    for param in model.parameters():\n",
    "        s += torch.abs(torch.sum(param)).item()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_updates = 5\n",
    "device_str = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "device = torch.device(device_str)\n",
    "kwargs = {\n",
    "    'batch_size': batch_size, \n",
    "    'max_epochs': 1, \n",
    "    'random_state': 42,\n",
    "    'module': Net,\n",
    "    'weight_decay': 1e-5,\n",
    "    'loss': nn.CrossEntropyLoss,\n",
    "    'optimizer': optim.Adagrad,\n",
    "    'device': device_str\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 1, 28, 28])\n",
      "torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "# Expected 4-dimensional input for 4-dimensional weight [32, 1, 3, 3], but got 2-dimensional input of size [32, 20] instead\n",
    "X, y = make_classification(n_samples=batch_size * n_updates, n_features=784)\n",
    "# match MNIST X\n",
    "X.resize((640, 28, 28))\n",
    "X = torch.from_numpy(X)\n",
    "X = X.unsqueeze(1)\n",
    "X = X.float()\n",
    "X.to(device)\n",
    "# match MNIST y\n",
    "y = torch.from_numpy(y)\n",
    "y.to(device)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adadamp import DaskClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2747.1799091994762\n"
     ]
    }
   ],
   "source": [
    "# call fit with whole dataset\n",
    "est1 = DaskClassifier(**kwargs)\n",
    "est1.fit(X, y)\n",
    "print(get_model_weights(est1.module_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set rand\n",
      "2078.9833680465817\n"
     ]
    }
   ],
   "source": [
    "# run partial fit many times\n",
    "est2 = DaskClassifier(**kwargs)\n",
    "for k in range(n_updates):\n",
    "    idx = np.arange(batch_size * k, batch_size * (k + 1)).astype(int)\n",
    "    est2.partial_fit(X[idx], y[idx])\n",
    "print(get_model_weights(est2.module_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ae87c128f730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(get_model_weights(est1.module_), get_model_weights(est2.module_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
